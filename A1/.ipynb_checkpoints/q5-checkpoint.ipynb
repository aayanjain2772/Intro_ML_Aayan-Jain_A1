{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Concrete Compressive Strength Regression Analysis\n",
    "# \n",
    "# In this notebook, we explore the differences between linear and polynomial regression on the Concrete Compressive Strength Dataset. We will:\n",
    "# \n",
    "# - Load and preprocess the data\n",
    "# - Train and evaluate a linear regression model\n",
    "# - Train and evaluate polynomial regression models (degrees 2, 3, and 4)\n",
    "# - Visualize and compare the results\n",
    "# - Discuss the bias-variance tradeoff observed in these models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## (a) Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/Concrete_Data.xls\"\n",
    "df = pd.read_excel(url)\n",
    "\n",
    "print(\"Dataset Head:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values per Column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "# Split the dataset into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"\\nTraining set size:\", X_train.shape)\n",
    "print(\"Testing set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## (b) Implementing Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the linear regression model\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_lin = lin_reg.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "mse_lin = mean_squared_error(y_test, y_pred_lin)\n",
    "r2_lin = r2_score(y_test, y_pred_lin)\n",
    "\n",
    "print(\"Linear Regression Performance:\")\n",
    "print(\"Mean Squared Error (MSE):\", mse_lin)\n",
    "print(\"Coefficient of Determination (R²):\", r2_lin)\n",
    "\n",
    "# Plot predicted vs. actual values for linear regression\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred_lin, alpha=0.6, label=\"Predicted vs. Actual\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label=\"Perfect Prediction\")\n",
    "plt.xlabel(\"Actual Compressive Strength\")\n",
    "plt.ylabel(\"Predicted Compressive Strength\")\n",
    "plt.title(\"Linear Regression: Predicted vs. Actual\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## (c) Implementing Polynomial Regression (Degrees 2, 3, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the degrees we want to test\n",
    "degrees = [2, 3, 4]\n",
    "\n",
    "# Dictionaries to store performance metrics and predictions for each polynomial degree\n",
    "mse_poly = {}\n",
    "r2_poly = {}\n",
    "y_pred_poly = {}\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "for i, degree in enumerate(degrees):\n",
    "    # Transform the features for the current polynomial degree\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "    \n",
    "    # Train the model on the polynomial features\n",
    "    poly_reg = LinearRegression()\n",
    "    poly_reg.fit(X_train_poly, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = poly_reg.predict(X_test_poly)\n",
    "    y_pred_poly[degree] = y_pred\n",
    "    \n",
    "    # Evaluate performance\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse_poly[degree] = mse\n",
    "    r2_poly[degree] = r2\n",
    "    \n",
    "    print(f\"Polynomial Degree {degree} Performance:\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"Coefficient of Determination (R²): {r2}\\n\")\n",
    "    \n",
    "    # Plot predicted vs. actual values for current polynomial degree\n",
    "    plt.subplot(1, len(degrees), i+1)\n",
    "    plt.scatter(y_test, y_pred, alpha=0.6, label=\"Predicted vs. Actual\")\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label=\"Perfect Prediction\")\n",
    "    plt.xlabel(\"Actual\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    plt.title(f\"Poly Degree {degree}\")\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## (d) Visualizing & Comparing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined plot for comparison\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_test, color=\"black\", alpha=0.5, label=\"Actual Data\")  # This shows the perfect prediction line\n",
    "\n",
    "# Plot linear regression predictions\n",
    "plt.scatter(y_test, y_pred_lin, alpha=0.6, label=\"Linear Regression\")\n",
    "\n",
    "# Plot polynomial regression predictions for each degree\n",
    "colors = {2: \"blue\", 3: \"green\", 4: \"orange\"}\n",
    "for degree in degrees:\n",
    "    plt.scatter(y_test, y_pred_poly[degree], alpha=0.6, label=f\"Poly Degree {degree}\", color=colors[degree])\n",
    "\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label=\"Perfect Prediction\")\n",
    "plt.xlabel(\"Actual Compressive Strength\")\n",
    "plt.ylabel(\"Predicted Compressive Strength\")\n",
    "plt.title(\"Model Comparison: Predicted vs. Actual\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Summarize the performance metrics\n",
    "print(\"Performance Summary:\")\n",
    "print(\"Linear Regression -> MSE: {:.4f}, R²: {:.4f}\".format(mse_lin, r2_lin))\n",
    "for degree in degrees:\n",
    "    print(f\"Polynomial Degree {degree} -> MSE: {mse_poly[degree]:.4f}, R²: {r2_poly[degree]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## (e) Bias-Variance Tradeoff Analysis\n",
    "# \n",
    "# **Discussion:**\n",
    "# \n",
    "# - **High Bias / Low Variance:**  \n",
    "#   The **linear regression** model is simple and might not capture the complex nonlinear relationships in the data. This simplicity typically results in high bias (underfitting) but low variance.\n",
    "# \n",
    "# - **Low Bias / High Variance:**  \n",
    "#   The **polynomial regression model with degree 4** is very flexible and can closely follow the training data, capturing noise in addition to the underlying trend. This results in low bias but high variance (overfitting), which may hurt performance on unseen data.\n",
    "# \n",
    "# - **Balanced Bias and Variance:**  \n",
    "#   A **polynomial model with degree 2 or 3** may strike a better balance between bias and variance. These models are flexible enough to capture the non-linear patterns without overfitting as much as a higher degree polynomial.\n",
    "# \n",
    "# **Why Higher-Degree Polynomials Tend to Overfit:**\n",
    "# \n",
    "# Higher-degree polynomials have many parameters, which allow them to fit the training data very closely—even the noise. Although this leads to a very low error on the training set (low bias), it often results in large fluctuations when predicting unseen data (high variance). This phenomenon is known as overfitting, where the model performs well on training data but poorly generalizes to new data."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
